{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Puppet Bootcamp by School of Devops This is a Lab Guide which goes along with the Zero to Puppet Course by School of Devops. For information about the devops trainign courses visit schoolofdevops.com . Team Gourav Shah","title":"Home"},{"location":"#welcome-to-puppet-bootcamp-by-school-of-devops","text":"This is a Lab Guide which goes along with the Zero to Puppet Course by School of Devops. For information about the devops trainign courses visit schoolofdevops.com .","title":"Welcome to Puppet Bootcamp by School of Devops"},{"location":"#team","text":"Gourav Shah","title":"Team"},{"location":"Chapter01/","text":"How I got started with Puppet and Devops ? As Georg Buchner said: We are only puppets, our strings are being pulled by unknown forces. My journey with Puppet began back in 2008, when as I was part of the Ops Team managing web scale infrastructure for a SaaS company. Our team consisted of ops engineers in India and US working out of their respective timezones, keeping lights on 24x7. As part of day to day operations, all of us would make ad hoc changes to the servers, and not always communicate back with the team on the other side of the globe. We did not have daily sync up meetings either. As a result of this ad hoc, inconsistent setup, regularly, issues would pop up with the product, in pre production/integration as well as in production environments. Being in charge of triaging, my team would spend a lot of time flipping through logs, doing root cause analysis and figuring out whether its a problem due to inconsistent configurations or a actual code related issue. Tired of this fire fighting, we started looking for solutions to help us efficiently manage this environment. And thats when we came across Puppet, which was popular, was already picked by likes of google, and had an active community around it. We started using it to setup the infrastructure as well as manage changes through a centralized console. Results were immediate, and tangible. After implementing puppet based configuration management system, We now had a centralized tool which streamlined our process of managing configurations. This resulted in minimal ad hoc changes and consistency across the environments. Visibility was another important outcome. Since we started writing infrastructure as a Code, everyone including the developers had visibility into the way infrastructure was configured. All one had to do was look at the svn/git repository, the last commits to know what changes were made, my whom and when. What more, developers could even tweak the application properties in their own integration environments. Error rates , specially related to configurations dropped significantly, giving us more time back in our day, to focus on scale and other important issues. That was the beginning of my journey with devops automation tools, which also includes exposure to Chef, and Ansible. Puppet was the first kid on the block, and has come a long way from the time it was created by Luke Kanies along with initial developers in 2005, to become a very matured and a indispensable tool in the kitty of a devops engineer. Before we start looking into what makes puppet a excellent choice for a automation tool, lets first understand what configuration management is about. Infrastructure Life Events and Puppet If you are the one who is in the business of managing more than a handful of systems, you should be familiar with the term \"Configuration Management\" (not to confuse with traditional Software Configuration Management or SCM). Be it physical servers, virtual machines or cloud based setup, infrastructure typically goes through the following life events, Provisioning Provision servers - physical, virtual or cloud. This is where the servers are brought into being. Install Operating System either using manual/automated install process or using an image/template. Configuration Management Base Systems Configurations: Prepare the systems with the base configurations such as users, packages, security configurations, network setup etc. Tech Stack: install and configure services such as apache, tomcat, middle wares, setup cron jobs, install and configure databases etc. Application: Deploy the application code on top of the tech stack configured. This is where the code written by your team gets deployed with relevant configurations. Change Management Configurations made during the initial setup do not remain do not last for a life time. Infrastructure is in the constant state of flux and evolves over time. Change management involves, Updating configurations parameters across a class of servers eg. update port that web server is running on. Deploying new versions of the application code, push security patches etc, install additional services. Puppet serves as a excellent tool for Configuration Management as well as Change Management. And along with tools such as Razor, Cloud Plugins, Vagrant, Terraform it could also automate provisioning of servers too. However puppet as a tool by itself does have an ability to provision and comes in to play once the Operating System is installed and puppet agent is setup. If you are looking for a tool which could also provision servers, and do it effectively, you should consider Ansible. Evolution of Configuration Management The need for managing configurations and ongoing changes had been a challenge which has seen various approaches. Lets have a look at the evolution of configuration management, Manual As systems engineers, we almost always begin configuring systems by hand, in a ad hoc manner. This approach is the easiest, and useful when you have only a handful of systems to manage, simple configurations, and where you do not have repeatable tasks or updates. However, as you start growing, this crude approach quickly gets out of control. It also involves manual processes, which mandates a operator to be present, and is prone to errors or omissions. Scripts Scripts allow one to take a sequence of commands to run and put it in a procedural program. Whenever there is need to repeat the process, scripts come in very handy. Some of the popular scripting languages amongst the systems personnel include shell/bash, perl, python, ruby or powershell. Scripts are almost always the first approach towards automating manual tasks. However, scripts are not scalable or flexible enough to manage a sophisticated infrastructure spanning across multitude of environments or the ones involving multiple different operating systems etc. Configuration Management and Software Configuration Management Software Configuration Management is referred to often with context of Revision Control which is about tracking changes to the application code. This is just one part of a larger field of Configuration Management. Golden Images/ Templates Golden images, or templates, or simply os images, are probably the quickest way to deploy servers complete with configurations, specially in virtual or cloud environments. Images are nothing but pre baked templates with operations system files, applications, and configurations. Take any cloud provider, and one of the first components to choose while you provision a server is the images. A lot of organizations these days package their products in the form of images such as ova, vmdk or even vagrant's box format. However images have one major problem i.e. change management. Every time there is an update, even a single line change, one needs to build a new image. Not only this complete system image needs to be distributed but also existing systems need to be replaced with the new image. Imagine doing that in a dynamic environment involving frequent updates across hundreds of servers. That could get too cumbersome. And thats where the need to come up with a new approach. Infrastructure as a Code \"Infrastructure as a Code\" or \"Programmable Infrastructure\" is where today's generation tools such as Puppet, Chef, Ansible, Salt fit in. These tools essentially allow one to write the state of the infrastructure using a higher level descriptive language and store it as a code. Since this is a code, one could bring in the best practices that developers have been following for years e.g. using revision control systems, use of sophisticated editors, test driven development, peer programming etc. You could even build the complete infrastructure from scratch in case of a disaster, as long as you have the code repository, compute resources and data backups in place. Since this code is written in a simple declarative syntax, it is self documenting and offers visibility to all stakeholders into the way infrastructure is built and configured. Approach Advantages Disadvantages Manual simple ad hoc, error prone, inconsistent, not repeatable Scripts repeatable, automated procedural, not scalable, inflexible Images repeatable, automated size, change management is not easy Infrastructure as a Code repeatable, flexible, scalable, automated, consistent agent based, learning curve Why to use Puppet ? Now that we have started discussion on Infrastructure as a Code, specifically Puppet, lets discuss about the specific features of puppet that make it a useful tool for configuration and change management. Declarative vs Procedural Approach Scripts take a procedural approach towards automation. With scripts, we focus on the how part. e.g. how to install a package, how to create a user, how to modify it later, how to do it on a specific platform. And if you would want to add a support for another platform, you may have to add additional procedure and write a conditional to check for the platform and call the relevant code. This involves a lot of efforts. On the other hand, Puppet takes a declarative approach towards automation. With Puppet, our focus changes from how part to what . Instead of writing procedures, we start using a simple declarative syntax to define the desired state of infrastructure. Let me explain this with an analogy. Lets say we want to build a house. When we set out to do so, we hire a contractor, who in turns has a team of construction workers who know how to build it brick by brick. They do all the hard work to bring our house into a reality. Thats the how part. On the other hand, you have a Architect. Lets take a moment and think about what he or she does. An Architect creates a plan, a blue print, which is nothing but a description of how your house should look like. The architect envisions the end state of your house, thinks about what should it consists of, breaks it down into components, and starts creating specification for each. He would then stitch it together to create a blueprint of our house, and hands it to the contractor to go and build it. This is the how part. Thats exactly what we would start doing with puppet, only difference being, we write the specification for desired state of IT infrastructure. Resource Abstraction Layer We just learnt about puppet allowing us to write the desired state of the infrastructure using a descriptive language. Now this concept is brought into a reality with the its Domain Specific Language(DSL) which consists of a Resource Abstraction Layer (RAL). Lets describe how this works, TODO : Create an image for each step below. Puppet looks at infrastructure as a collection of entities to manage e.g. package, service, user, network interface etc. It then takes the procedures, the actual logic to manage these entities and bundles it into something called as Providers . Providers are platform specific. That way, each entity may have multiple providers e.g. managing user on linux vs osx vs windows. On top of these procedures, puppet creates an abstraction layer. Instead of defining the procedures, it offers the users a simple declarative syntax to define the state of the entity and its properties, in the form of Resources . Puppet, then does the translation between Resources and Providers, and calls the procedure to put the entity in to the desired state just as described by the user. This behavior allows the users of the puppet to create policies stating what which entities should be present or absent, with what properties. Convergence and Idempotence Puppet reads the resources, calls the relevant providers for the platform it runs on, and ensures the desired state of the resource is achieved. While it does so, it may need to make changes to the system. But what if the resource has already achieved the desired state and needs no further updates? Puppet has the built in intelligence to know what is the current state of the resource is. Instead of making changes blindly, it first compares the current state of the resource with the desired state, and the makes a decision whether it requires any changes, and if yes, what changes to make. This process is called as convergence. TODO : Draw diagrams, maybe just a flowchart e.g. Lets assume we have written a resource to create a user with a password. user{'xyz': uid => '501', gid => '501', home => '/home/xyz', password => '$1$foYKL0zO$elXbUOb/JjHqS4aI8O25i.' } First time puppet applies this resource on the system, the user may not exist. Puppet detects the current state, compares it with the desired state which mentions it should exist, and finds the configuration drift. It then creates the user with the password to bring the current state to desired state. Lets assume we run puppet again to apply the same resource. This time too it will compare the desired state with current state. Since the user is already present with the password provided, it deems no changes necessary. Instead of attempting to create the user again, it will skip the resource and move on to the next one. Lets assume we updated the password information for the user in our code description of the resource, and excute puppet. This time, while comparing the current state with desired state, it detects that the user is present, but the password is updated. It does not attempt to create a user, but only changes one property i.e. password. Idempotence is a useful property to ensures that puppet maintains the state of the infrastructure such that its always in the policy. This also makes change management easier as one could keep running puppet as a service which invokes itself at regular intervals, pulls the changes, and apply only what is changed. Centralized Configuration Management System A typical installation of puppet involves a Puppet Master, which is a centralized management console and Agents runnings on every node managed. Any changes to nodes have to go through the Puppet Master. This streamlines the process of pushing updated. Instead of iterating over a list of hosts using a for loop or other such methods, or logging into each system to make changes, all you need to do is push updates to Puppet Master, from where those are automatically propogated to the nodes. TODO Pull Approach While puppet offers a centralized management approach, it works unlike most client server schemes. Instead of pushing updates to the nodes from master, its the duty of puppet agent to go the master, pull changes, and apply. Pull method offers more flexibility and scalability for the following reasons, Each node could decide how frequently or infrequently it should update. Some systems need frequent updates, where as others need not be updated for weeks. This could be controlled at per client level. No need to manage inventory and connection details on the master. Nodes could come and go, and could be configured based on dynamic rules to classify them based on certain property e.g. host names, environments, or even hardware addresses. With push based approach, master must have a ability reach out and connect to each node managed in order to configure it. A lot of times you may have a master on a cloud or in a separate data center than nodes being managed, which could be behind a firewall or NAT device in a private network. In case of pull method, as long as the master is available on a well known address, and is reachable from the nodes, configurations can be pulled and applied. Code vs Data A lot of applications that we configure on our servers are generic eg. apache, tomcat, mysql, mongo. These applications have a install base of hundreds of thousands of servers, used by organizations across the globe. Ever wondered how these become specific to your environment ? Even though you use the same apache web server used by many others, its how you configure it makes the difference. Even in single organization, you may have a apache server which behaves differently in different environment based on the configuration profile created. The process of setting up an application involves, Installing the generic application either from a source, package or a repository. Adding data. This where you set configuration parameters e.g. port, user, max connections, webroot for apache. Start, enable the service. Puppet allows separation of code and data. Using Puppet's DSL, we write infrastructure code to install packages start services etc. Code is generic. Puppet's variables/parameters/facts, scopes, templates, along with tools such as Hiera and ENC provide a way to create different configuration profiles specific to different nodes, environments, platforms etc. Shared Library of Infrastructure Code With puppet's ability to separate code and configuration data, the declarative code that you write in the form of modules with puppet becomes generic enough to be shared and be reused. And since this code is in the version control, hosted services such as github offer the perfect means to publish this code. As you start writing code with puppet, you would discover about puppet forge, a library of community written modules. At the time of writing, there are more than 4000 modules available on puppet forge. Similar to a lot of open source code, you need not re invent the wheel. For most open source applications, you would find very sophisticated modules which you could use without even single line change. Download the modules, install it on your own puppet master, add configuration profile, and off you go. Cloud Integrations With emergence of cloud, computing is moving towards the utility model. More and more organizations have already migrated or contemplating to migrate a partial or whole of their computing setup to cloud. And with that happening, which ever automation tool that you would consider, needs to have a close integration with the cloud platform that you plan to use. Provisioning of infrastructure components before puppet comes in and starts configuring There are two ways Puppet provides a way for this, Through library of custom resources/libraries which allow one to write provisioning of cloud components in the form of resources. Cloud specific tools e.g. Cloudformation on AWS or Heat on Openstack are some of the tools which help provision components which are specific to that cloud and then call puppet to do the configurations. Third party tools such as Vagrant, Terraform have in turn ability to talk to multiple cloud providers. These tools typically provision servers on the cloud and then hand it off to puppet for configurations. Iterative Approach to Automation However convinced you are with Puppet, scrapping your existing automation tool overnight for a shiny new tool may have unknown risks attached. More over, it may could be challenging to get a buy in from your management to invest in time, money and resources to implement a new solution without showing them the value. With puppet, you could take a iterative approach towards automation. You could start with a single application, or even a single entity such as a system user to manage. Once you see the value, show it to all stake holders, get a buy in and move to the next application, one at a time. Device Support Managing configurations on systems running common operating systems such as windows, linux, os x, where puppet agent application can be installed is easy. Its a completely different beast when it comes to managing configurations on devices running their own specialized version of operating systems/firmwares. Examples are configuring CISCO's network switches routers, EMC's storage array. Along with programmable infrastructures, new concepts such as Software Defined Networking(SDN) and Software Defined Storage(SDS) are taking root and changing the way devices are being managed. Puppet supports managing devices in two ways, Devices that are based on linux and have puppet agent ported to run on those can be configured the same way as other generic systems. Sub set of devices that do not have puppet agent can still be configured with puppet's device support over ssh/telnet. For such devices, puppet uses push instead of pull approach. Audit and Compliance With ability to define the state of the infrastructure components as a code and then converge, one could easily codify the infrastructure policies and have them enforced. Puppets ability to test, log changes, and reporting mechanisms help keeping a trail of the state of the systems and its components over time and track who made changes, when, if there are any nodes which have fallen out of policy etc. When to Use Puppet ? You should consider using puppet for the following purposes, Configuration Management + Change Management: You have many nodes to deploy with changes happening often. You need to update the nodes and applications running on those often. Compliance and Audit : When your organization has to comply to policies and you need an ability to convert those policies into a code which would auto correct and bring the nodes into the policy in case of configuration drifts. You also need to audit the systems regularly and prepare reports to find out which nodes have drifted away from the policy etc. as well as mitigate such issues. Software Delivery : If you are in business of building software and delivering as ova images or similar, puppet is better approach to deliver the product and push updates to it. Who is it for? Systems Administrators/Engineers who are managing systems at scale and need to install, configure, patch, monitor and maintain systems and prepared reports for. Application Operations Engineers who are responsible for installing, configuring, integrating, monitoring, maintaining application infrastructures. Build and release engineers who are in charge of setting up environments for CI/CD cycles, as well as deploy/release applications to production environments. Network Engineers who configure and maintain networking devices such as CISCO Routers and Switches at scale. Storage Administrators who configure and maintain storage devices. Developers who are building application delivery to their customers. Also as users of the develops tools, developers may need to change application properties for the environments that they create/use. What Puppet is not? Graphical Management Tool (e.g. SCCM): If you are looking for a tool which would allow you to manage everything through a graphical interface without writing any code or without ever having to use an editor, well puppet is not the tool for you. I have come across many engineers, who say \"well, the capabilities of puppet sounds great, but can I do all of this using a GUI where I can just click click and get things done.... ? \" Well, its infrastructure as a code is what we are talking about. Even though enterprise puppet puppet offers a nice GUI, its mostly for reporting and classifications. Since I started using puppet and similar tools, I have been using text editors more often. Automated Testing Tool ( e.g. selenium ): Its not a silver bullet. Its not one solutions to all. I meet a lot of QA folks who have heard that puppet would automate everything and you could use it for testing too. Well, there is always a special purpose tool for each task and the application testing is not puppet's ball game. Sure puppet could help in testing by letting you automate the process of building and configuring a fresh environment to run your tests inside, and give you ability to do it repeatedly. It also gives you a way to test infrastrcuture code. However, its not a test automation tool. Pure Application Deployment and Orchestration Tool: Even though Puppet has been talking about application orchestration, if you are looking for a tool purely for application deployments, rolling updates, canary releases, orchestrated deployments over multiple hosts, you have tools which do it better. A few tools I could suggest you for application deployment and orchestration are Asible, Capistrano, Code Deploy which are push based, and work better in such scenarios. Agent less Management System: Except for a sub set of network devices, puppet mandates running agents on each node being managed. In fact its designed to be heavy on the agent side which is responsible to initiate communication with the master, pull policies, enforce and report back. If you need a agent less management system, puppet is not the one. Again, I would suggest using Ansible in such cases, which works over ssh and is agent less. Software Configuration Management(SCM) Tool SCM is a part of the larger Configuration Management and typically refers to the practice of revision/version control. Puppet is not the tool which does the version control, however it can be used to replicate and manage software configurations across a cluster of nodes. A one stop Devops solutions Puppet Use Cases/ Customer Stories Puppet vs Chef Puppet vs Ansible Puppet vs Docker Upgrading from Puppet 3 to Puppet 4 Using Tidy to clean up unwanted files","title":"Intro"},{"location":"Chapter01/#how-i-got-started-with-puppet-and-devops","text":"As Georg Buchner said: We are only puppets, our strings are being pulled by unknown forces. My journey with Puppet began back in 2008, when as I was part of the Ops Team managing web scale infrastructure for a SaaS company. Our team consisted of ops engineers in India and US working out of their respective timezones, keeping lights on 24x7. As part of day to day operations, all of us would make ad hoc changes to the servers, and not always communicate back with the team on the other side of the globe. We did not have daily sync up meetings either. As a result of this ad hoc, inconsistent setup, regularly, issues would pop up with the product, in pre production/integration as well as in production environments. Being in charge of triaging, my team would spend a lot of time flipping through logs, doing root cause analysis and figuring out whether its a problem due to inconsistent configurations or a actual code related issue. Tired of this fire fighting, we started looking for solutions to help us efficiently manage this environment. And thats when we came across Puppet, which was popular, was already picked by likes of google, and had an active community around it. We started using it to setup the infrastructure as well as manage changes through a centralized console. Results were immediate, and tangible. After implementing puppet based configuration management system, We now had a centralized tool which streamlined our process of managing configurations. This resulted in minimal ad hoc changes and consistency across the environments. Visibility was another important outcome. Since we started writing infrastructure as a Code, everyone including the developers had visibility into the way infrastructure was configured. All one had to do was look at the svn/git repository, the last commits to know what changes were made, my whom and when. What more, developers could even tweak the application properties in their own integration environments. Error rates , specially related to configurations dropped significantly, giving us more time back in our day, to focus on scale and other important issues. That was the beginning of my journey with devops automation tools, which also includes exposure to Chef, and Ansible. Puppet was the first kid on the block, and has come a long way from the time it was created by Luke Kanies along with initial developers in 2005, to become a very matured and a indispensable tool in the kitty of a devops engineer. Before we start looking into what makes puppet a excellent choice for a automation tool, lets first understand what configuration management is about.","title":"How I got started with Puppet and Devops ?"},{"location":"Chapter01/#infrastructure-life-events-and-puppet","text":"If you are the one who is in the business of managing more than a handful of systems, you should be familiar with the term \"Configuration Management\" (not to confuse with traditional Software Configuration Management or SCM). Be it physical servers, virtual machines or cloud based setup, infrastructure typically goes through the following life events, Provisioning Provision servers - physical, virtual or cloud. This is where the servers are brought into being. Install Operating System either using manual/automated install process or using an image/template. Configuration Management Base Systems Configurations: Prepare the systems with the base configurations such as users, packages, security configurations, network setup etc. Tech Stack: install and configure services such as apache, tomcat, middle wares, setup cron jobs, install and configure databases etc. Application: Deploy the application code on top of the tech stack configured. This is where the code written by your team gets deployed with relevant configurations. Change Management Configurations made during the initial setup do not remain do not last for a life time. Infrastructure is in the constant state of flux and evolves over time. Change management involves, Updating configurations parameters across a class of servers eg. update port that web server is running on. Deploying new versions of the application code, push security patches etc, install additional services. Puppet serves as a excellent tool for Configuration Management as well as Change Management. And along with tools such as Razor, Cloud Plugins, Vagrant, Terraform it could also automate provisioning of servers too. However puppet as a tool by itself does have an ability to provision and comes in to play once the Operating System is installed and puppet agent is setup. If you are looking for a tool which could also provision servers, and do it effectively, you should consider Ansible.","title":"Infrastructure Life Events and Puppet"},{"location":"Chapter01/#evolution-of-configuration-management","text":"The need for managing configurations and ongoing changes had been a challenge which has seen various approaches. Lets have a look at the evolution of configuration management,","title":"Evolution of Configuration Management"},{"location":"Chapter01/#manual","text":"As systems engineers, we almost always begin configuring systems by hand, in a ad hoc manner. This approach is the easiest, and useful when you have only a handful of systems to manage, simple configurations, and where you do not have repeatable tasks or updates. However, as you start growing, this crude approach quickly gets out of control. It also involves manual processes, which mandates a operator to be present, and is prone to errors or omissions.","title":"Manual"},{"location":"Chapter01/#scripts","text":"Scripts allow one to take a sequence of commands to run and put it in a procedural program. Whenever there is need to repeat the process, scripts come in very handy. Some of the popular scripting languages amongst the systems personnel include shell/bash, perl, python, ruby or powershell. Scripts are almost always the first approach towards automating manual tasks. However, scripts are not scalable or flexible enough to manage a sophisticated infrastructure spanning across multitude of environments or the ones involving multiple different operating systems etc.","title":"Scripts"},{"location":"Chapter01/#configuration-management-and-software-configuration-management","text":"Software Configuration Management is referred to often with context of Revision Control which is about tracking changes to the application code. This is just one part of a larger field of Configuration Management.","title":"Configuration Management and  Software Configuration Management"},{"location":"Chapter01/#golden-images-templates","text":"Golden images, or templates, or simply os images, are probably the quickest way to deploy servers complete with configurations, specially in virtual or cloud environments. Images are nothing but pre baked templates with operations system files, applications, and configurations. Take any cloud provider, and one of the first components to choose while you provision a server is the images. A lot of organizations these days package their products in the form of images such as ova, vmdk or even vagrant's box format. However images have one major problem i.e. change management. Every time there is an update, even a single line change, one needs to build a new image. Not only this complete system image needs to be distributed but also existing systems need to be replaced with the new image. Imagine doing that in a dynamic environment involving frequent updates across hundreds of servers. That could get too cumbersome. And thats where the need to come up with a new approach.","title":"Golden Images/ Templates"},{"location":"Chapter01/#infrastructure-as-a-code","text":"\"Infrastructure as a Code\" or \"Programmable Infrastructure\" is where today's generation tools such as Puppet, Chef, Ansible, Salt fit in. These tools essentially allow one to write the state of the infrastructure using a higher level descriptive language and store it as a code. Since this is a code, one could bring in the best practices that developers have been following for years e.g. using revision control systems, use of sophisticated editors, test driven development, peer programming etc. You could even build the complete infrastructure from scratch in case of a disaster, as long as you have the code repository, compute resources and data backups in place. Since this code is written in a simple declarative syntax, it is self documenting and offers visibility to all stakeholders into the way infrastructure is built and configured. Approach Advantages Disadvantages Manual simple ad hoc, error prone, inconsistent, not repeatable Scripts repeatable, automated procedural, not scalable, inflexible Images repeatable, automated size, change management is not easy Infrastructure as a Code repeatable, flexible, scalable, automated, consistent agent based, learning curve","title":"Infrastructure as a Code"},{"location":"Chapter01/#why-to-use-puppet","text":"Now that we have started discussion on Infrastructure as a Code, specifically Puppet, lets discuss about the specific features of puppet that make it a useful tool for configuration and change management.","title":"Why to use Puppet ?"},{"location":"Chapter01/#declarative-vs-procedural-approach","text":"Scripts take a procedural approach towards automation. With scripts, we focus on the how part. e.g. how to install a package, how to create a user, how to modify it later, how to do it on a specific platform. And if you would want to add a support for another platform, you may have to add additional procedure and write a conditional to check for the platform and call the relevant code. This involves a lot of efforts. On the other hand, Puppet takes a declarative approach towards automation. With Puppet, our focus changes from how part to what . Instead of writing procedures, we start using a simple declarative syntax to define the desired state of infrastructure. Let me explain this with an analogy. Lets say we want to build a house. When we set out to do so, we hire a contractor, who in turns has a team of construction workers who know how to build it brick by brick. They do all the hard work to bring our house into a reality. Thats the how part. On the other hand, you have a Architect. Lets take a moment and think about what he or she does. An Architect creates a plan, a blue print, which is nothing but a description of how your house should look like. The architect envisions the end state of your house, thinks about what should it consists of, breaks it down into components, and starts creating specification for each. He would then stitch it together to create a blueprint of our house, and hands it to the contractor to go and build it. This is the how part. Thats exactly what we would start doing with puppet, only difference being, we write the specification for desired state of IT infrastructure.","title":"Declarative vs Procedural Approach"},{"location":"Chapter01/#resource-abstraction-layer","text":"We just learnt about puppet allowing us to write the desired state of the infrastructure using a descriptive language. Now this concept is brought into a reality with the its Domain Specific Language(DSL) which consists of a Resource Abstraction Layer (RAL). Lets describe how this works, TODO : Create an image for each step below. Puppet looks at infrastructure as a collection of entities to manage e.g. package, service, user, network interface etc. It then takes the procedures, the actual logic to manage these entities and bundles it into something called as Providers . Providers are platform specific. That way, each entity may have multiple providers e.g. managing user on linux vs osx vs windows. On top of these procedures, puppet creates an abstraction layer. Instead of defining the procedures, it offers the users a simple declarative syntax to define the state of the entity and its properties, in the form of Resources . Puppet, then does the translation between Resources and Providers, and calls the procedure to put the entity in to the desired state just as described by the user. This behavior allows the users of the puppet to create policies stating what which entities should be present or absent, with what properties.","title":"Resource Abstraction Layer"},{"location":"Chapter01/#convergence-and-idempotence","text":"Puppet reads the resources, calls the relevant providers for the platform it runs on, and ensures the desired state of the resource is achieved. While it does so, it may need to make changes to the system. But what if the resource has already achieved the desired state and needs no further updates? Puppet has the built in intelligence to know what is the current state of the resource is. Instead of making changes blindly, it first compares the current state of the resource with the desired state, and the makes a decision whether it requires any changes, and if yes, what changes to make. This process is called as convergence. TODO : Draw diagrams, maybe just a flowchart e.g. Lets assume we have written a resource to create a user with a password. user{'xyz': uid => '501', gid => '501', home => '/home/xyz', password => '$1$foYKL0zO$elXbUOb/JjHqS4aI8O25i.' } First time puppet applies this resource on the system, the user may not exist. Puppet detects the current state, compares it with the desired state which mentions it should exist, and finds the configuration drift. It then creates the user with the password to bring the current state to desired state. Lets assume we run puppet again to apply the same resource. This time too it will compare the desired state with current state. Since the user is already present with the password provided, it deems no changes necessary. Instead of attempting to create the user again, it will skip the resource and move on to the next one. Lets assume we updated the password information for the user in our code description of the resource, and excute puppet. This time, while comparing the current state with desired state, it detects that the user is present, but the password is updated. It does not attempt to create a user, but only changes one property i.e. password. Idempotence is a useful property to ensures that puppet maintains the state of the infrastructure such that its always in the policy. This also makes change management easier as one could keep running puppet as a service which invokes itself at regular intervals, pulls the changes, and apply only what is changed.","title":"Convergence and Idempotence"},{"location":"Chapter01/#centralized-configuration-management-system","text":"A typical installation of puppet involves a Puppet Master, which is a centralized management console and Agents runnings on every node managed. Any changes to nodes have to go through the Puppet Master. This streamlines the process of pushing updated. Instead of iterating over a list of hosts using a for loop or other such methods, or logging into each system to make changes, all you need to do is push updates to Puppet Master, from where those are automatically propogated to the nodes. TODO","title":"Centralized Configuration Management System"},{"location":"Chapter01/#pull-approach","text":"While puppet offers a centralized management approach, it works unlike most client server schemes. Instead of pushing updates to the nodes from master, its the duty of puppet agent to go the master, pull changes, and apply. Pull method offers more flexibility and scalability for the following reasons, Each node could decide how frequently or infrequently it should update. Some systems need frequent updates, where as others need not be updated for weeks. This could be controlled at per client level. No need to manage inventory and connection details on the master. Nodes could come and go, and could be configured based on dynamic rules to classify them based on certain property e.g. host names, environments, or even hardware addresses. With push based approach, master must have a ability reach out and connect to each node managed in order to configure it. A lot of times you may have a master on a cloud or in a separate data center than nodes being managed, which could be behind a firewall or NAT device in a private network. In case of pull method, as long as the master is available on a well known address, and is reachable from the nodes, configurations can be pulled and applied.","title":"Pull Approach"},{"location":"Chapter01/#code-vs-data","text":"A lot of applications that we configure on our servers are generic eg. apache, tomcat, mysql, mongo. These applications have a install base of hundreds of thousands of servers, used by organizations across the globe. Ever wondered how these become specific to your environment ? Even though you use the same apache web server used by many others, its how you configure it makes the difference. Even in single organization, you may have a apache server which behaves differently in different environment based on the configuration profile created. The process of setting up an application involves, Installing the generic application either from a source, package or a repository. Adding data. This where you set configuration parameters e.g. port, user, max connections, webroot for apache. Start, enable the service. Puppet allows separation of code and data. Using Puppet's DSL, we write infrastructure code to install packages start services etc. Code is generic. Puppet's variables/parameters/facts, scopes, templates, along with tools such as Hiera and ENC provide a way to create different configuration profiles specific to different nodes, environments, platforms etc.","title":"Code vs Data"},{"location":"Chapter01/#shared-library-of-infrastructure-code","text":"With puppet's ability to separate code and configuration data, the declarative code that you write in the form of modules with puppet becomes generic enough to be shared and be reused. And since this code is in the version control, hosted services such as github offer the perfect means to publish this code. As you start writing code with puppet, you would discover about puppet forge, a library of community written modules. At the time of writing, there are more than 4000 modules available on puppet forge. Similar to a lot of open source code, you need not re invent the wheel. For most open source applications, you would find very sophisticated modules which you could use without even single line change. Download the modules, install it on your own puppet master, add configuration profile, and off you go.","title":"Shared Library of Infrastructure Code"},{"location":"Chapter01/#cloud-integrations","text":"With emergence of cloud, computing is moving towards the utility model. More and more organizations have already migrated or contemplating to migrate a partial or whole of their computing setup to cloud. And with that happening, which ever automation tool that you would consider, needs to have a close integration with the cloud platform that you plan to use. Provisioning of infrastructure components before puppet comes in and starts configuring There are two ways Puppet provides a way for this, Through library of custom resources/libraries which allow one to write provisioning of cloud components in the form of resources. Cloud specific tools e.g. Cloudformation on AWS or Heat on Openstack are some of the tools which help provision components which are specific to that cloud and then call puppet to do the configurations. Third party tools such as Vagrant, Terraform have in turn ability to talk to multiple cloud providers. These tools typically provision servers on the cloud and then hand it off to puppet for configurations.","title":"Cloud Integrations"},{"location":"Chapter01/#iterative-approach-to-automation","text":"However convinced you are with Puppet, scrapping your existing automation tool overnight for a shiny new tool may have unknown risks attached. More over, it may could be challenging to get a buy in from your management to invest in time, money and resources to implement a new solution without showing them the value. With puppet, you could take a iterative approach towards automation. You could start with a single application, or even a single entity such as a system user to manage. Once you see the value, show it to all stake holders, get a buy in and move to the next application, one at a time.","title":"Iterative Approach to Automation"},{"location":"Chapter01/#device-support","text":"Managing configurations on systems running common operating systems such as windows, linux, os x, where puppet agent application can be installed is easy. Its a completely different beast when it comes to managing configurations on devices running their own specialized version of operating systems/firmwares. Examples are configuring CISCO's network switches routers, EMC's storage array. Along with programmable infrastructures, new concepts such as Software Defined Networking(SDN) and Software Defined Storage(SDS) are taking root and changing the way devices are being managed. Puppet supports managing devices in two ways, Devices that are based on linux and have puppet agent ported to run on those can be configured the same way as other generic systems. Sub set of devices that do not have puppet agent can still be configured with puppet's device support over ssh/telnet. For such devices, puppet uses push instead of pull approach.","title":"Device Support"},{"location":"Chapter01/#audit-and-compliance","text":"With ability to define the state of the infrastructure components as a code and then converge, one could easily codify the infrastructure policies and have them enforced. Puppets ability to test, log changes, and reporting mechanisms help keeping a trail of the state of the systems and its components over time and track who made changes, when, if there are any nodes which have fallen out of policy etc.","title":"Audit and Compliance"},{"location":"Chapter01/#when-to-use-puppet","text":"You should consider using puppet for the following purposes, Configuration Management + Change Management: You have many nodes to deploy with changes happening often. You need to update the nodes and applications running on those often. Compliance and Audit : When your organization has to comply to policies and you need an ability to convert those policies into a code which would auto correct and bring the nodes into the policy in case of configuration drifts. You also need to audit the systems regularly and prepare reports to find out which nodes have drifted away from the policy etc. as well as mitigate such issues. Software Delivery : If you are in business of building software and delivering as ova images or similar, puppet is better approach to deliver the product and push updates to it.","title":"When to Use Puppet ?"},{"location":"Chapter01/#who-is-it-for","text":"Systems Administrators/Engineers who are managing systems at scale and need to install, configure, patch, monitor and maintain systems and prepared reports for. Application Operations Engineers who are responsible for installing, configuring, integrating, monitoring, maintaining application infrastructures. Build and release engineers who are in charge of setting up environments for CI/CD cycles, as well as deploy/release applications to production environments. Network Engineers who configure and maintain networking devices such as CISCO Routers and Switches at scale. Storage Administrators who configure and maintain storage devices. Developers who are building application delivery to their customers. Also as users of the develops tools, developers may need to change application properties for the environments that they create/use.","title":"Who is it for?"},{"location":"Chapter01/#what-puppet-is-not","text":"Graphical Management Tool (e.g. SCCM): If you are looking for a tool which would allow you to manage everything through a graphical interface without writing any code or without ever having to use an editor, well puppet is not the tool for you. I have come across many engineers, who say \"well, the capabilities of puppet sounds great, but can I do all of this using a GUI where I can just click click and get things done.... ? \" Well, its infrastructure as a code is what we are talking about. Even though enterprise puppet puppet offers a nice GUI, its mostly for reporting and classifications. Since I started using puppet and similar tools, I have been using text editors more often. Automated Testing Tool ( e.g. selenium ): Its not a silver bullet. Its not one solutions to all. I meet a lot of QA folks who have heard that puppet would automate everything and you could use it for testing too. Well, there is always a special purpose tool for each task and the application testing is not puppet's ball game. Sure puppet could help in testing by letting you automate the process of building and configuring a fresh environment to run your tests inside, and give you ability to do it repeatedly. It also gives you a way to test infrastrcuture code. However, its not a test automation tool. Pure Application Deployment and Orchestration Tool: Even though Puppet has been talking about application orchestration, if you are looking for a tool purely for application deployments, rolling updates, canary releases, orchestrated deployments over multiple hosts, you have tools which do it better. A few tools I could suggest you for application deployment and orchestration are Asible, Capistrano, Code Deploy which are push based, and work better in such scenarios. Agent less Management System: Except for a sub set of network devices, puppet mandates running agents on each node being managed. In fact its designed to be heavy on the agent side which is responsible to initiate communication with the master, pull policies, enforce and report back. If you need a agent less management system, puppet is not the one. Again, I would suggest using Ansible in such cases, which works over ssh and is agent less. Software Configuration Management(SCM) Tool SCM is a part of the larger Configuration Management and typically refers to the practice of revision/version control. Puppet is not the tool which does the version control, however it can be used to replicate and manage software configurations across a cluster of nodes. A one stop Devops solutions Puppet Use Cases/ Customer Stories","title":"What Puppet is not?"},{"location":"Chapter01/#puppet-vs-chef","text":"","title":"Puppet vs Chef"},{"location":"Chapter01/#puppet-vs-ansible","text":"","title":"Puppet vs Ansible"},{"location":"Chapter01/#puppet-vs-docker","text":"","title":"Puppet vs Docker"},{"location":"Chapter01/#upgrading-from-puppet-3-to-puppet-4","text":"","title":"Upgrading from Puppet 3 to Puppet 4"},{"location":"Chapter01/#using-tidy-to-clean-up-unwanted-files","text":"","title":"Using Tidy to clean up unwanted files"},{"location":"Chapter04/","text":"Modules Update code dir to use your current workspace On puppet master puppet cp -r /etc/puppetlabs/code /workspace/code Update config in the server's config file /etc/puppetlabs/puppetserver/conf.d/puppetserver.conf and update master-code-dir: /etc/puppetlabs/code to master-code-dir: /workspace/code (assuming you are using /workspace as your working/developement directory on the puppet master to store the code at ) Restart Puppet Server shell service puppetserver restart This may take time. Generating Modules Change into the directory for production env sh cd /workspace/code/environments/production/modules Using puppet module command, generate the scaffolding for java and tomcat modules bash puppet module generate --skip-interview user-java puppet module generate --skip-interview gshah-tomcat Writing classes file: modules/java/manifests/init.pp class java { package { [ 'epel-release', 'java-1.7.0-openjdk'] : ensure => installed, } } Node Definitions - Applying the code To apply the default class from java module, create a node definition create file: environments/production/manifests/app.pp add the node definition node 'node1' { include java } To apply, login to node1 and run puppet agent ssh devops@node1 sudo su puppet agent -t Writing the class to install tomcat file: modules/tomcat/manifests/install.pp class tomcat::install { include java package { [ 'tomcat', 'tomcat-webapps' ]: ensure => installed, require => Package['epel-release'] } } Add tomcat::install to node definition for node1 which should now look like node 'node1' { include java include tomcat::install } Apply on node1 by running puppet agent [on node1, as root] puppet agent -t Nano Project Now that you have learnt how to write a manifest and apply, and have gone through the class naming conventions, you have been tasked to create the following classe with the specifications as give below, class : tomcat::service resource : service name : tomcat ensure : running enable : true service resource should have a dependency on install class apply it to node1 by updating the node definition. Validate by visiting the IP address of the server and port 8081. Note : Tomcat may take up to 10mins to come up for the first time. This is discussed in details on this page https://wiki.apache.org/tomcat/HowTo/FasterStartUp at the Entropy Source section. We are going to apply that fix in the subsequenct sections. Also bootstrap node2 ( configure it to talk to the master), create a node definition identical to node1, and apply. Validate that the tomcat service is started on port 8082. Simplify Run List file: modules/tomcat/manifests/init.pp class tomcat { include tomcat::install include tomcat::service } And production/manifests/app.pp node 'node1' { include tomcat } node 'node2' { include tomcat } Question : Why are we not including java anymore? Managing Files Create file create directory to hold files : modules/tomcat/files create a file modules/tomcat/files/tomcat.conf and add the content from https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24 Create a class tomcat::config to copy this file to destinition tomcat::config class class tomcat::config { file { '/etc/tomcat/tomcat.conf': source => 'puppet:///modules/tomcat/tomcat.conf', owner => 'tomcat', group => 'tomcat', mode => '0644', notify => Service['tomcat'] } } Call it from tomcat class (init.pp) class tomcat { include tomcat::install include tomcat::config include tomcat::service } Apply on Node1 and Node2","title":"Modules"},{"location":"Chapter04/#modules","text":"","title":"Modules"},{"location":"Chapter04/#update-code-dir-to-use-your-current-workspace","text":"On puppet master puppet cp -r /etc/puppetlabs/code /workspace/code Update config in the server's config file /etc/puppetlabs/puppetserver/conf.d/puppetserver.conf and update master-code-dir: /etc/puppetlabs/code to master-code-dir: /workspace/code (assuming you are using /workspace as your working/developement directory on the puppet master to store the code at ) Restart Puppet Server shell service puppetserver restart This may take time.","title":"Update code dir to use your current workspace"},{"location":"Chapter04/#generating-modules","text":"Change into the directory for production env sh cd /workspace/code/environments/production/modules Using puppet module command, generate the scaffolding for java and tomcat modules bash puppet module generate --skip-interview user-java puppet module generate --skip-interview gshah-tomcat","title":"Generating Modules"},{"location":"Chapter04/#writing-classes","text":"file: modules/java/manifests/init.pp class java { package { [ 'epel-release', 'java-1.7.0-openjdk'] : ensure => installed, } }","title":"Writing classes"},{"location":"Chapter04/#node-definitions-applying-the-code","text":"To apply the default class from java module, create a node definition create file: environments/production/manifests/app.pp add the node definition node 'node1' { include java } To apply, login to node1 and run puppet agent ssh devops@node1 sudo su puppet agent -t","title":"Node Definitions - Applying the code"},{"location":"Chapter04/#writing-the-class-to-install-tomcat","text":"file: modules/tomcat/manifests/install.pp class tomcat::install { include java package { [ 'tomcat', 'tomcat-webapps' ]: ensure => installed, require => Package['epel-release'] } } Add tomcat::install to node definition for node1 which should now look like node 'node1' { include java include tomcat::install } Apply on node1 by running puppet agent [on node1, as root] puppet agent -t","title":"Writing the class to install tomcat"},{"location":"Chapter04/#nano-project","text":"Now that you have learnt how to write a manifest and apply, and have gone through the class naming conventions, you have been tasked to create the following classe with the specifications as give below, class : tomcat::service resource : service name : tomcat ensure : running enable : true service resource should have a dependency on install class apply it to node1 by updating the node definition. Validate by visiting the IP address of the server and port 8081. Note : Tomcat may take up to 10mins to come up for the first time. This is discussed in details on this page https://wiki.apache.org/tomcat/HowTo/FasterStartUp at the Entropy Source section. We are going to apply that fix in the subsequenct sections. Also bootstrap node2 ( configure it to talk to the master), create a node definition identical to node1, and apply. Validate that the tomcat service is started on port 8082.","title":"Nano Project"},{"location":"Chapter04/#simplify-run-list","text":"file: modules/tomcat/manifests/init.pp class tomcat { include tomcat::install include tomcat::service } And production/manifests/app.pp node 'node1' { include tomcat } node 'node2' { include tomcat } Question : Why are we not including java anymore?","title":"Simplify Run List"},{"location":"Chapter04/#managing-files","text":"Create file create directory to hold files : modules/tomcat/files create a file modules/tomcat/files/tomcat.conf and add the content from https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24 Create a class tomcat::config to copy this file to destinition tomcat::config class class tomcat::config { file { '/etc/tomcat/tomcat.conf': source => 'puppet:///modules/tomcat/tomcat.conf', owner => 'tomcat', group => 'tomcat', mode => '0644', notify => Service['tomcat'] } } Call it from tomcat class (init.pp) class tomcat { include tomcat::install include tomcat::config include tomcat::service } Apply on Node1 and Node2","title":"Managing Files"},{"location":"Chapter05/","text":"Parameters and Facts Playing with Scopes app.pp $color = 'blue' $car = 'maruti' node 'node1' { include tomcat } node 'node2' { $color = 'green' include tomcat } Create tomcat::scope class class tomcat::scope { notify{\"print the scope\": message => \" FAVOURITE COLOR : ${color} FAVOURITE CAR : ${car} \" } } Add this class to init.pp class tomcat { include tomcat::scope include tomcat::install include tomcat::config include tomcat::service } Apply on both node1 and node2 and see the difference? Question: Why does it print two different values? Inheritance and story of params.pp create file: modules/tomcat/params.pp class tomcat::params { $color = 'white' $car = 'figo' } Update tomcat::scope definition to inherit tomcat::params. Lets also define $color in this child class. class tomcat::scope inherits tomcat::params{ $color = 'yellow' notify{\"print the scope\": message => \" FAVOURITE COLOR : ${color} FAVOURITE CAR : ${car} \" } } Parameterising Tomcat Configs tomcat::params class tomcat::params { $color = 'white' $car = 'figo' $user = 'tomcat' $group = 'tomcat' $config_path = '/etc/tomcat/tomcat.conf' $packages = [ 'tomcat', 'tomcat-webapps' ] $service_name = 'tomcat' $service_state = running } tomcat (init.pp) class tomcat inherits tomcat::params{ include tomcat::scope include tomcat::install include tomcat::config include tomcat::service } class tomcat::install class tomcat::install inherits tomcat{ include java package { $::tomcat::packages: ensure => installed, require => Package['epel-release'] } } class tomcat::config class tomcat::config inherits tomcat{ file { $::tomcat::config_path: source => 'puppet:///modules/tomcat/tomcat.conf', owner => $::tomcat::user, group => $::tomcat::group, mode => '0644', notify => Service['tomcat'] } } class tomcat::service class tomcat::service inherits tomcat{ service { $::tomcat::service_name: ensure => $::tomcat::service_state, enable => true, require => Class['tomcat::install'], } } Creating base module cd /workspace/code/environments/production/modules puppet module generate --skip-interview user-base mv /workspace/base.pp base/manifests/init.pp Add class to modules/base/manifests/init.pp. Code for this class can be availed from https://gist.github.com/initcron/dd302fe9fabcc9a1af071394bf8e8d6a Add the base class to one of the nodes, and see if you could apply e.g. for node2 definition in app.pp node 'node2' { include base $color = 'green' include tomcat } Question : What happens when you apply this class on node2 by running puppet agent ?? Lets use params.pp for doing platform specific configurations, class base::params { case $::os['family'] { 'Debian': { $ntp_service = 'ntp' } 'RedHat': { $ntp_service = 'ntpd' } } } And to use these params, we need to * inherit base::params in base class (init.pp) * parameterize the service name Update init.pp with the above two changes. Here is the updated file for your reference https://gist.github.com/initcron/c8b6530dbae41c47c0d864d2a594844e Using Facts Lets also start using facts inside modules. To do this, lets create a file resource which generates /etc/motd and prints information about the system Update modules/base/manifests/init.pp and add the following resource. file { '/etc/motd': ensure => file, owner => 'root', content => \" This server is a property of XYZ Inc. SYSTEM INFO ============ Hostname : ${::fqdn} IP Address : ${::ipaddress} Memory : ${::memory['system']['total']} Cores : ${::processors['count']} OS : ${::os['distro']['description']} \" } Apply on all nodes and validate.","title":"Parameters and Facts"},{"location":"Chapter05/#parameters-and-facts","text":"","title":"Parameters and Facts"},{"location":"Chapter05/#playing-with-scopes","text":"app.pp $color = 'blue' $car = 'maruti' node 'node1' { include tomcat } node 'node2' { $color = 'green' include tomcat } Create tomcat::scope class class tomcat::scope { notify{\"print the scope\": message => \" FAVOURITE COLOR : ${color} FAVOURITE CAR : ${car} \" } } Add this class to init.pp class tomcat { include tomcat::scope include tomcat::install include tomcat::config include tomcat::service } Apply on both node1 and node2 and see the difference? Question: Why does it print two different values?","title":"Playing with Scopes"},{"location":"Chapter05/#inheritance-and-story-of-paramspp","text":"create file: modules/tomcat/params.pp class tomcat::params { $color = 'white' $car = 'figo' } Update tomcat::scope definition to inherit tomcat::params. Lets also define $color in this child class. class tomcat::scope inherits tomcat::params{ $color = 'yellow' notify{\"print the scope\": message => \" FAVOURITE COLOR : ${color} FAVOURITE CAR : ${car} \" } }","title":"Inheritance and story of params.pp"},{"location":"Chapter05/#parameterising-tomcat-configs","text":"tomcat::params class tomcat::params { $color = 'white' $car = 'figo' $user = 'tomcat' $group = 'tomcat' $config_path = '/etc/tomcat/tomcat.conf' $packages = [ 'tomcat', 'tomcat-webapps' ] $service_name = 'tomcat' $service_state = running } tomcat (init.pp) class tomcat inherits tomcat::params{ include tomcat::scope include tomcat::install include tomcat::config include tomcat::service } class tomcat::install class tomcat::install inherits tomcat{ include java package { $::tomcat::packages: ensure => installed, require => Package['epel-release'] } } class tomcat::config class tomcat::config inherits tomcat{ file { $::tomcat::config_path: source => 'puppet:///modules/tomcat/tomcat.conf', owner => $::tomcat::user, group => $::tomcat::group, mode => '0644', notify => Service['tomcat'] } } class tomcat::service class tomcat::service inherits tomcat{ service { $::tomcat::service_name: ensure => $::tomcat::service_state, enable => true, require => Class['tomcat::install'], } }","title":"Parameterising Tomcat Configs"},{"location":"Chapter05/#creating-base-module","text":"cd /workspace/code/environments/production/modules puppet module generate --skip-interview user-base mv /workspace/base.pp base/manifests/init.pp Add class to modules/base/manifests/init.pp. Code for this class can be availed from https://gist.github.com/initcron/dd302fe9fabcc9a1af071394bf8e8d6a Add the base class to one of the nodes, and see if you could apply e.g. for node2 definition in app.pp node 'node2' { include base $color = 'green' include tomcat } Question : What happens when you apply this class on node2 by running puppet agent ?? Lets use params.pp for doing platform specific configurations, class base::params { case $::os['family'] { 'Debian': { $ntp_service = 'ntp' } 'RedHat': { $ntp_service = 'ntpd' } } } And to use these params, we need to * inherit base::params in base class (init.pp) * parameterize the service name Update init.pp with the above two changes. Here is the updated file for your reference https://gist.github.com/initcron/c8b6530dbae41c47c0d864d2a594844e","title":"Creating base module"},{"location":"Chapter05/#using-facts","text":"Lets also start using facts inside modules. To do this, lets create a file resource which generates /etc/motd and prints information about the system Update modules/base/manifests/init.pp and add the following resource. file { '/etc/motd': ensure => file, owner => 'root', content => \" This server is a property of XYZ Inc. SYSTEM INFO ============ Hostname : ${::fqdn} IP Address : ${::ipaddress} Memory : ${::memory['system']['total']} Cores : ${::processors['count']} OS : ${::os['distro']['description']} \" } Apply on all nodes and validate.","title":"Using Facts"},{"location":"Chapter06/","text":"Templates Converting tomcat.conf into a template We always start with the original file (e.g. https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24 ) Create file structure to store the templates Create a director modules/manifests/templates Create a ERB file for tomcat.conf at modules/manifests/templates/tomcat.conf.erb Copy over the contents of the original tomcat.conf. You could use the link above as a sample content What could go wrong ? You may have named templates directory as template Note the singular vs plural. It should be plural, with s . There is also a possibility that you have a typo in the name. You may have created templates directory at a wrong path. It MUST be at ...modules/tomcat/templates Now lets start converting the file into a template. How do we do that? * Keep the property names intact. e.g. JAVA_HOME or TOMCAT_USER * Start replacing the values, with template variables. This is where ERB tags are handy. e.g. Original content such as this TOMCAT_USER=\"tomcat\" SHUTDOWN_WAIT=\"30\" becomes TOMCAT_USER=\"<%= @user >\" SHUTDOWN_WAIT=\"<%= @shutdown_wait >\" The template variables which start with @var need to be defined as well. Do that in tomcat::params . We already have user defined, lets define the shutdown_wait. What value do we define here? Well params.pp contains the sane default. So whatever came with the package/configs, and was present in tomcat.conf by default is what we use. e.g. $shutdown_wait = 30 TIP : Its always useful to define the params first in params.pp before replacing the values in the template with ERB tags. That way, you would not have to go figure what were the default values, as once replaces, those values are gone. Its also easir to just copy over the params back as template variables. Exercise Update the following properties in tomcat.conf in the template, and define the defaults in params.pp TOMCAT_CFG_LOADED JAVA_HOME xms xmx maxpermsize CATALINA_BASE JASPER_HOME CATALINA_TMPDIR SECURITY_MANAGER SHUTDOWN_VERBOSE CATALINA_PID References : tomcat.conf.erb : https://gist.github.com/initcron/71e939a22e018dbc27dd4ae7deb3a55e tomcat::params : https://gist.github.com/initcron/b08de87a1e835852ac00772252a71a97 Calling templates from config class Creating templates and params does not have an effect on the system unless you start generating the configs using templates. Currently we are using a file resource to generate this file. Lets convert that to using a template. In tomcat::config class, update property of the file resource from source => 'puppet:///modules/tomcat/tomcat.conf', to content => template('tomcat/tomcat.conf.erb'), Here is the code after making that change for your reference https://gist.github.com/initcron/87d99703590825716bed515f7e8bf64f","title":"Templates"},{"location":"Chapter06/#templates","text":"","title":"Templates"},{"location":"Chapter06/#converting-tomcatconf-into-a-template","text":"We always start with the original file (e.g. https://gist.github.com/initcron/01f8554fba3305a1bceee9df5ff0aa24 ) Create file structure to store the templates Create a director modules/manifests/templates Create a ERB file for tomcat.conf at modules/manifests/templates/tomcat.conf.erb Copy over the contents of the original tomcat.conf. You could use the link above as a sample content What could go wrong ? You may have named templates directory as template Note the singular vs plural. It should be plural, with s . There is also a possibility that you have a typo in the name. You may have created templates directory at a wrong path. It MUST be at ...modules/tomcat/templates Now lets start converting the file into a template. How do we do that? * Keep the property names intact. e.g. JAVA_HOME or TOMCAT_USER * Start replacing the values, with template variables. This is where ERB tags are handy. e.g. Original content such as this TOMCAT_USER=\"tomcat\" SHUTDOWN_WAIT=\"30\" becomes TOMCAT_USER=\"<%= @user >\" SHUTDOWN_WAIT=\"<%= @shutdown_wait >\" The template variables which start with @var need to be defined as well. Do that in tomcat::params . We already have user defined, lets define the shutdown_wait. What value do we define here? Well params.pp contains the sane default. So whatever came with the package/configs, and was present in tomcat.conf by default is what we use. e.g. $shutdown_wait = 30 TIP : Its always useful to define the params first in params.pp before replacing the values in the template with ERB tags. That way, you would not have to go figure what were the default values, as once replaces, those values are gone. Its also easir to just copy over the params back as template variables.","title":"Converting tomcat.conf into a template"},{"location":"Chapter06/#exercise","text":"Update the following properties in tomcat.conf in the template, and define the defaults in params.pp TOMCAT_CFG_LOADED JAVA_HOME xms xmx maxpermsize CATALINA_BASE JASPER_HOME CATALINA_TMPDIR SECURITY_MANAGER SHUTDOWN_VERBOSE CATALINA_PID","title":"Exercise"},{"location":"Chapter06/#references","text":"tomcat.conf.erb : https://gist.github.com/initcron/71e939a22e018dbc27dd4ae7deb3a55e tomcat::params : https://gist.github.com/initcron/b08de87a1e835852ac00772252a71a97","title":"References :"},{"location":"Chapter06/#calling-templates-from-config-class","text":"Creating templates and params does not have an effect on the system unless you start generating the configs using templates. Currently we are using a file resource to generate this file. Lets convert that to using a template. In tomcat::config class, update property of the file resource from source => 'puppet:///modules/tomcat/tomcat.conf', to content => template('tomcat/tomcat.conf.erb'), Here is the code after making that change for your reference https://gist.github.com/initcron/87d99703590825716bed515f7e8bf64f","title":"Calling templates from config class"},{"location":"deploy_app/","text":"Deploy Sysfoo to Application Servers Create a defined type to deploy a warfile file: modules/tomcat/manifests/deploy.pp define tomcat::deploy( $deploy_url, $checksum_value, $checksum = 'md5', $deploy_path = $::tomcat::deploy_path ) { file { \"${deploy_path}/${name}.war\" : source => \"${deploy_url}\", owner => $::tomcat::user, group => $::tomcat::group, checksum_value => \"${checksum_value}\", checksum => \"${checksum}\", notify => Exec['purge_context'], } exec { 'purge_context': command => \"rm -rf ${deploy_path}/${name}\", path => '/usr/bin:/usr/sbin:/bin', refreshonly => true, notify => Service['tomcat'], } } Define relevant params file: modules/tomcat/manifests/params.pp $deploy_path = '/var/lib/tomcat/webapps' Use the defined type file: code/environments/production/manifests/app.pp tomcat::deploy { \"sysfoo\": deploy_url => 'https://6-94848332-gh.circle-artifacts.com/0/tmp/circle-artifacts.3grfYBu/sysfoo.war', checksum_value => 'e1611c2f62b5c01e7f620a19a73446ea', checksum => 'md5' }","title":"Deploying App"},{"location":"deploy_app/#deploy-sysfoo-to-application-servers","text":"","title":"Deploy Sysfoo to Application Servers"},{"location":"deploy_app/#create-a-defined-type-to-deploy-a-warfile","text":"file: modules/tomcat/manifests/deploy.pp define tomcat::deploy( $deploy_url, $checksum_value, $checksum = 'md5', $deploy_path = $::tomcat::deploy_path ) { file { \"${deploy_path}/${name}.war\" : source => \"${deploy_url}\", owner => $::tomcat::user, group => $::tomcat::group, checksum_value => \"${checksum_value}\", checksum => \"${checksum}\", notify => Exec['purge_context'], } exec { 'purge_context': command => \"rm -rf ${deploy_path}/${name}\", path => '/usr/bin:/usr/sbin:/bin', refreshonly => true, notify => Service['tomcat'], } }","title":"Create a defined type to deploy a warfile"},{"location":"deploy_app/#define-relevant-params","text":"file: modules/tomcat/manifests/params.pp $deploy_path = '/var/lib/tomcat/webapps'","title":"Define relevant params"},{"location":"deploy_app/#use-the-defined-type","text":"file: code/environments/production/manifests/app.pp tomcat::deploy { \"sysfoo\": deploy_url => 'https://6-94848332-gh.circle-artifacts.com/0/tmp/circle-artifacts.3grfYBu/sysfoo.war', checksum_value => 'e1611c2f62b5c01e7f620a19a73446ea', checksum => 'md5' }","title":"Use the defined type"},{"location":"install/","text":"Installation With Vagrant # Import Vagrant Tempalte # Open iterm/ git bash and browse to the dir where the box file is copied. Run the following # From puppet directory $ vagrant box add puppet-template devops-training-centos-v2.box # Validate $ vagrant box list puppet-template (virtualbox, 0) # To Bring up the VMs with Vagrant and Virtualbox # Open iterm or git bash from virtual/multi directory # Open 3 different windows and cd into virtual/multi dir in each # bring up the VMs as cd virtual/multi $ vagrant up master $ vagrant up web #$ vagrant up db # Open three different windows, one for master, one for web and one for db servers, and login $ vagrant ssh master $ vagrant ssh web #$ vagrant ssh db #On Puppet Master $ sudo su $ yum install puppetserver puppet-agent -y $ service puppetserver start # Validate $ service puppetserver status #On Puppet Agents : all nodes $ sudo su $ yum install puppet-agent $ service puppet status $ service puppet start # Validate $ service puppet status # On Master, check for certificate request # Outstanding $ puppet cert list # All $ puppet cert list -a # Sign $ puppet cert sign -a # On agents run puppet puppet agent -t","title":"Puppet Installation using Vagrant"},{"location":"install/#installation","text":"","title":"Installation"},{"location":"install/#with-vagrant","text":"# Import Vagrant Tempalte # Open iterm/ git bash and browse to the dir where the box file is copied. Run the following # From puppet directory $ vagrant box add puppet-template devops-training-centos-v2.box # Validate $ vagrant box list puppet-template (virtualbox, 0) # To Bring up the VMs with Vagrant and Virtualbox # Open iterm or git bash from virtual/multi directory # Open 3 different windows and cd into virtual/multi dir in each # bring up the VMs as cd virtual/multi $ vagrant up master $ vagrant up web #$ vagrant up db # Open three different windows, one for master, one for web and one for db servers, and login $ vagrant ssh master $ vagrant ssh web #$ vagrant ssh db #On Puppet Master $ sudo su $ yum install puppetserver puppet-agent -y $ service puppetserver start # Validate $ service puppetserver status #On Puppet Agents : all nodes $ sudo su $ yum install puppet-agent $ service puppet status $ service puppet start # Validate $ service puppet status # On Master, check for certificate request # Outstanding $ puppet cert list # All $ puppet cert list -a # Sign $ puppet cert sign -a # On agents run puppet puppet agent -t","title":"With Vagrant"},{"location":"preface/","text":"Preface This is an example of \"frontmatter\", which comes before the main text of the book.","title":"Preface"},{"location":"preface/#preface","text":"This is an example of \"frontmatter\", which comes before the main text of the book.","title":"Preface"},{"location":"readthedocs/","text":".. Zero to Puppet documentation master file, created by sphinx-quickstart on Tue Dec 5 09:30:07 2017. You can adapt this file completely to your liking, but it should at least contain the root toctree directive. Welcome to Zero to Puppet's documentation! .. toctree:: :maxdepth: 2 :caption: Contents: Indices and tables :ref: genindex :ref: modindex :ref: search","title":"Readthedocs"},{"location":"readthedocs/#welcome-to-zero-to-puppets-documentation","text":".. toctree:: :maxdepth: 2 :caption: Contents:","title":"Welcome to Zero to Puppet's documentation!"},{"location":"readthedocs/#indices-and-tables","text":":ref: genindex :ref: modindex :ref: search","title":"Indices and tables"},{"location":"rspec/","text":"Rspec Set the Path The following path need to be set in order to use rake, rspec etc. export PATH=$PATH:/opt/puppetlabs/puppet/bin/ echo \"export PATH=$PATH:/opt/puppetlabs/puppet/bin/\" >> ~/.bashrc source ~/.bashrc Install Required Tools gem install --no-ri --no-rdoc puppet-lint puppet-syntax puppetlabs_spec_helper cd modules/java rspec-puppet-init gem install bundler bundle install Validate rake help rspec --help Smoke testing rspec and rake on Java module Observe Rakefile in modules/java Validate and run rspec tests rake validate rake spec rake test echo $? metadata may need to be changed to { \"name\": \"gshah-java\", \"version\": \"0.1.0\", \"author\": \"gshah\", \"summary\": \"this module installs openjdk 7 on RedHat\", \"license\": \"Apache-2.0\", \"source\": \"\", \"project_page\": null, \"issues_url\": null, \"dependencies\": [ {\"name\":\"puppetlabs-stdlib\",\"version_requirement\":\"= 4.17.0\"} ], \"data_provider\": null } Writing first unit test spec for tomcat file: modules/tomcat/.fixtures.yml fixtures: symlinks: tomcat: \"#{source_dir}\" java: \"#{source_dir}/../java\" Smoke Test rake validate [fix issues if any until the above command is successful] Create a simple unit test for class tomcat (init.pp) file: modules/tomcat/specs/classes/init_spec.rb require 'spec_helper' describe 'tomcat' do context 'with default values for all parameters' do it { should contain_class('tomcat') } end it { should contain_class('tomcat::install') } it { should contain_class('tomcat::config') } it { should contain_class('tomcat::service') } end Run Tests rake spec Creating specs for tomcat::config file: specs/classes/config_spec.rb require 'spec_helper' describe 'tomcat::config' do it { should contain_class('tomcat::config') } it { is_expected.to compile } it { is_expected.to contain_file('/etc/tomcat/tomcat.conf').with({ :mode => '0644', :owner => 'tomcat', :group => 'tomcat', }).that_notifies('Service[tomcat]') } end Exercise Scanario 1 : Create a spec for service class which validates * if tomcat::service is defined * if it contains a service resource with * ensure value as running * enable set to true * requires on Class['tomcat::install'] Scanario 2 : Create a spec for base class which validates * if ::base class is defined * if it contains a service resource for ntp with * ensure value as running * enable set to true * Given the osfamily * as RedHat, service class should expect ntpd is the service name * as Debian, should expect ntp as the service name Reading List Unit Testing with Puppet https://puppet.com/blog/unit-testing-rspec-puppet-for-beginners Next Generation of Puppet Module Testing https://puppet.com/blog/next-generation-of-puppet-module-testing Rspec Matchers for Puppet http://rspec-puppet.com/matchers/ Puppet-rspec Tutorial http://rspec-puppet.com/tutorial/ Sample Unit Tests with Spec https://github.com/desc/puppet-reprepro/blob/master/spec/classes/init_spec.rb http://terrarum.net/blog/puppet-testing-part-1.html https://wikimatze.de/getting-started-with-rspec-puppet/","title":"Rspec"},{"location":"rspec/#rspec","text":"","title":"Rspec"},{"location":"rspec/#set-the-path","text":"The following path need to be set in order to use rake, rspec etc. export PATH=$PATH:/opt/puppetlabs/puppet/bin/ echo \"export PATH=$PATH:/opt/puppetlabs/puppet/bin/\" >> ~/.bashrc source ~/.bashrc","title":"Set the Path"},{"location":"rspec/#install-required-tools","text":"gem install --no-ri --no-rdoc puppet-lint puppet-syntax puppetlabs_spec_helper cd modules/java rspec-puppet-init gem install bundler bundle install Validate rake help rspec --help","title":"Install Required Tools"},{"location":"rspec/#smoke-testing-rspec-and-rake-on-java-module","text":"Observe Rakefile in modules/java Validate and run rspec tests rake validate rake spec rake test echo $? metadata may need to be changed to { \"name\": \"gshah-java\", \"version\": \"0.1.0\", \"author\": \"gshah\", \"summary\": \"this module installs openjdk 7 on RedHat\", \"license\": \"Apache-2.0\", \"source\": \"\", \"project_page\": null, \"issues_url\": null, \"dependencies\": [ {\"name\":\"puppetlabs-stdlib\",\"version_requirement\":\"= 4.17.0\"} ], \"data_provider\": null }","title":"Smoke testing rspec and rake on Java module"},{"location":"rspec/#writing-first-unit-test-spec-for-tomcat","text":"file: modules/tomcat/.fixtures.yml fixtures: symlinks: tomcat: \"#{source_dir}\" java: \"#{source_dir}/../java\" Smoke Test rake validate [fix issues if any until the above command is successful] Create a simple unit test for class tomcat (init.pp) file: modules/tomcat/specs/classes/init_spec.rb require 'spec_helper' describe 'tomcat' do context 'with default values for all parameters' do it { should contain_class('tomcat') } end it { should contain_class('tomcat::install') } it { should contain_class('tomcat::config') } it { should contain_class('tomcat::service') } end Run Tests rake spec","title":"Writing first unit test spec for tomcat"},{"location":"rspec/#creating-specs-for-tomcatconfig","text":"file: specs/classes/config_spec.rb require 'spec_helper' describe 'tomcat::config' do it { should contain_class('tomcat::config') } it { is_expected.to compile } it { is_expected.to contain_file('/etc/tomcat/tomcat.conf').with({ :mode => '0644', :owner => 'tomcat', :group => 'tomcat', }).that_notifies('Service[tomcat]') } end","title":"Creating specs for tomcat::config"},{"location":"rspec/#exercise","text":"Scanario 1 : Create a spec for service class which validates * if tomcat::service is defined * if it contains a service resource with * ensure value as running * enable set to true * requires on Class['tomcat::install'] Scanario 2 : Create a spec for base class which validates * if ::base class is defined * if it contains a service resource for ntp with * ensure value as running * enable set to true * Given the osfamily * as RedHat, service class should expect ntpd is the service name * as Debian, should expect ntp as the service name","title":"Exercise"},{"location":"rspec/#reading-list","text":"Unit Testing with Puppet https://puppet.com/blog/unit-testing-rspec-puppet-for-beginners Next Generation of Puppet Module Testing https://puppet.com/blog/next-generation-of-puppet-module-testing Rspec Matchers for Puppet http://rspec-puppet.com/matchers/ Puppet-rspec Tutorial http://rspec-puppet.com/tutorial/ Sample Unit Tests with Spec https://github.com/desc/puppet-reprepro/blob/master/spec/classes/init_spec.rb http://terrarum.net/blog/puppet-testing-part-1.html https://wikimatze.de/getting-started-with-rspec-puppet/","title":"Reading List"}]}